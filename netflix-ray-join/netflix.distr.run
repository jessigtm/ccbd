#!/bin/bash
#SBATCH -A your_project_code       # Replace with your actual allocation or remove if not needed
#SBATCH --job-name="netflix"
#SBATCH --output="netflix.distr.out"
#SBATCH --partition=compute
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=128
#SBATCH --mem=249208M
#SBATCH --export=ALL 
#SBATCH --time=29

module load python3

# Set your working directory path
SW=/path/to/netflix/data  # Replace this with a non-sensitive or relative path if possible

# Set up Python virtual environment
export PYTHON_ENV="$HOME/venv"
python3 -m venv $PYTHON_ENV
source "$PYTHON_ENV/bin/activate"
python3 -m pip install --upgrade pip
pip install -U "ray[default]"
pip install pandas
pip install pyarrow

# Setup Ray cluster
node_count=$SLURM_NNODES
echo "Number of nodes = " $node_count
nodes=$(scontrol show hostnames "$SLURM_JOB_NODELIST")
nodes_array=($nodes)

head_node=${nodes_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-addr)

port=6379
ip_head=$head_node_ip:$port
export ip_head
echo "Starting head node at $head_node"
srun --nodes=1 --ntasks=1 -w "$head_node" ray start --head --node-ip-address="$head_node_ip" --port=$port --num-cpus 64 --block &
sl
